\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage[backend=biber]{biblatex} %Imports biblatex package
\addbibresource{bibliography.bib} %Import the bibliography file

%opening
\title{Simulazione}
\author{angelo}

\begin{document}

\maketitle

\begin{abstract}
Simulazione modello di Hopfield variando la distribuzione dei pattern e la temperatura.
\end{abstract}

\section*{Introduzione}

Devo fare la seguente simulazione. Il mio modello è composto da $N$ neuroni $s_i$ (con $i=1\ldots N$) il cui stato in ogni istante è un elemento di $\{-1,+1 \}$, da $p$ pattern $\xi^\mu$ (con $\mu=1\ldots p$) che sono vettori in $\mathbb{R}^N$, estratti secondo una distribuzione di probabilità, e da dei coupling $J_{ij}$ per $i\neq j$ che sono numeri reali e dipendono dai pattern secondo la regola di Hebb:
\begin{equation}
 J_{ij}=\frac{1}{N}\sum_{\mu = 0}^p \xi_i^\mu \xi_j^\mu \ ,\ i\neq j .
 \label{eq:hebb}
\end{equation}
Notiamo che i coupling dipendono dall'estrazione iniziale dei pattern e da lì sono fissati.

L'energia di una configurazione è definita dalla seguente hamiltoniana:
\begin{equation}
 H(\underline{s}) = -\frac{1}{2} \sum_{i\neq j} J_{ij} s_i s_j\ .
 \label{eq:ham}
\end{equation}
\`{E} un sistema dinamico discreto che si muove secondo una dinamica di Glauber \cite{10.1063/1.1703954} con update sequenziale: in ogni step temporale viene scelto un neurone a caso e con la seguente probabilità cambierà valore (flipperà) o meno:
\[
 P(s_i(t+1)=s) = \frac{1 + s \tanh (\beta \phi_i(\underline{s}(t)))}{2} ,
\]
dove $\phi_i(\underline{s}(t))$ è il campo locale in $i$ al tempo $t$ è definito da:
\[
 \phi_i(\underline{s}(t)) = \sum_{j=1,j\neq i}^N J_{ij}s_j(t) ;
\]
e  $\beta = 1/T$ è l'inverso della temperatura $T$, che è un altro parametro del sistema ed è un numero reale non negativo. In particolare ci interessano i casi di temperatura nulla, vicino allo zero, temperatura critica e vicino alla temperatura critica

\section{Prima simulazione}

Estraggo un sample di $p$ pattern $\xi^\mu$ con $\mu=1\ldots p$, i.i.d. secondo la seguente distribuzione dipendende dal parametro $a$:
\[
 P(\xi^\mu)=\prod_{i=1}^N p(\xi_i^\mu),
\]
\[
 p(\xi_i^\mu) = \frac{a}{2\sqrt{2}} e^{-|\xi|/\sqrt{2}} + \frac{1-a}{2} \left[ \delta(\xi-1) + \delta(\xi+1) \right].
\]
Sulla base di questi pattern sono determinati i coupling $J_{ij}$ (usando l'eq. \ref{eq:hebb}), inizializzo il sistema sul primo pattern, faccio evolvere il sistema per un tempo $t_{max}$. Per ogni istante di tempo calcolo la magnetizzazione $m_1$ rispetto al primo pattern:
\[
 m_1(t)=\frac{1}{N}\sum_{i=1}^N \xi_i^1 s_i(t) .
\]
Mi stampo e plotto la magnetizzazione in funzione del tempo.

Ripeto per un certo numero di volte da estrazione dei pattern a produzione di magnetizzazione in funzione del tempo, poi faccio la media di $m_1$ rispetto ai vari sample estratti.

\subsection{Input, Output, Execution path}

\textbf{Input}: \begin{itemize}
\item $N$, è un numero intero positivo. Inizialmente provo con 1000; andrebbero fatte almeno due simulazioni con due valori diversi, magari uno il doppio dell'altro per motivi di scaling.
\item $p$, è un numero intero positivo. Inizio con 9 per essere nel limite di carico nullo (è minore di $1\%N=10$) e avere un numero dispari di pattern.
\item $a$, parametro da cui dipende la distribuzione dei pattern, è un numero reale tra 0 e 1.
\item $T$, la temperatura, un numero reale non nullo, ci interessano i valori vicino a 0 e alla temperatura critica.
\item $t_{max}$, per quanti sweep far evolvere il sistema, è un numero intero positivo. Inizio con $100$, ma devo guardare se la magnetizzazione circa smette di cambiare dopo $N$ step, in tal caso posso assumere che il sistema ha termalizzato.
\item $s$, il numero di sample dei pattern e la conseguente simulazione (stabilità primo pattern) da fare, è un numero intero positivo. Inizio con $20$.                                                                                                                                                                                                                                             \end{itemize}


\textbf{Output}:
\begin{itemize}
 %\item $m_1(t)$: magnetizzazione del primo pattern in funzione del tempo per ogni sample, in un formato CSV su due colonne: nella prima un numero progressivo che indica il tempo t, nella seconda un numero reale che indica $m_1(t)$.
 \item $(\overline{m_1(t)}, std(m_1(t)))$: media, rispetto ai vari sample, delle magnetizzazione del primo pattern in funzione del tempo, in un in un formato CSV su due colonne: nella prima un numero reale che indica $\overline{m_1(t)}$, nella seconda un numero reale che indica $std(m_1(t)))$.
\end{itemize}

\textbf{Execution path}
\begin{enumerate}
% \item da input a elenco $m_1(t)$ per sample.
 \item da input a elenco $(\overline{m_1(t)}, std(m_1(t)))$.
% \item da elenco $m_1(t)$ a plot.
 \item da elenco $(\overline{m_1(t)}, std(m_1(t)))$ a plot.
\end{enumerate}

\section{Seconda simulazione draft - mistura}

Come la prima ma partendo da una mistura (continua) e calcolando la magnetizzazione rispetto a tale mistura.
Nota: è normale esca la magnetizzazione più grande di 1 perché calcoliamo la magnetizzazione rispetto a cose continue.

\section{Terza simulazione - one sample every pattern init}

Now we can keep track of the module of the magnetization (becaus e the system has a $\mathbb{Z}_2$ simmetry) respect to every pattern and the energy (via eq. \ref{eq:ham}), we perform the simulation with only one sample, but we perform a simulation starting in every pattern.

\subsection{Motivation}

M said that maybe, due to small-scale effects, there is only one minimum. Moreover this simulation could be a nice way to esplorate what happened without the effects of averaging.

\subsection{Input - Output}

For the sake of simplicity we firstly run the simulation at zero temperature, so the parameter that varies along vary simulation is the parameter of the distribution $a$.


\subsubsection{IO - main}
\textbf{Input:}
\begin{itemize}
\item $N$, number of neurons, positive integer, default value 1000.
\item $p$, number of patterns, positive integer, default value 9.
\item $sweep_{max}$, ``time'' evolution of the system, for now 100, positive integer.
\item $a$, parameter that determines the distribution, real number between 0 and 1.
\item $T$, temperature, we are interested in values near 0, for now we will fix it at zero, non negative real number.
\end{itemize}
\textbf{Output:}
A three indices array: one for which pattern is the initial state of the system, one for the time express in term of sweeps, one for the magnetization which respect to and the energy of the system.

\subsubsection{IO - run}
\begin{itemize}
 \item[Input:] N, p, sweeps, a, T.
 \item[Output:] A csv file with in every column a magnetization respect to a pattern and the energy, starting from a pattern, and in every row the evolution time.
\end{itemize}

\subsubsection{IO - plot}
\begin{itemize}
 \item[Input:] A csv file with in every column a magnetization respect to a pattern or the energy, starting from a pattern, and in every row the evolution time. Its optional to give the input path or the output path; if input it is not given, it will take from the stdin; if output it is not given it will show the plot.
 \item[Output:] $p$ plots, for every starting point, i.e. every pattern, the temporal evolution of every magnetization and of the energy. Depending on the input the output will be showen or saved.
\end{itemize}

\section{Fourth simulation - hystograms magn one pattern init}

\subsection{Motivation}
When is performed the average respect to various samples, the magnetization respect to the first pattern is the unique mean magnetization that is not around zero is $m_1$, but the std of the others magnetizations are very high when $a$ is large enough, so we hypothize that we see zero magnetization due to the averaging. To delve into this we can obtain the hystograms of the magnetizations.

\section{Fifth simulation - random init}
We started at a random point and i see if the system finishes in a mixture, do multiple run keeping fixed the patterns sampled and varying the random starting point, and varying the parameter $a$. We'll hope that if $a$ is large enough it will finishes in a mixture.


\printbibliography

\end{document}
